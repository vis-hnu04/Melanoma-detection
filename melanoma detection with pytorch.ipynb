{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install wtfml==0.0.2\n!pip install pretrainedmodels\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport torch\nimport albumentations\n\nimport cv2\nimport numpy as np\nimport pandas as pd\n\n\nimport torch.nn as nn\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom torch.nn import functional as F\nfrom torchvision import transforms\n\nfrom torch.utils.data import Dataset\nfrom tqdm import tqdm\n\n\nfrom matplotlib import pyplot as plt\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nfrom wtfml.utils import EarlyStopping\nfrom wtfml.engine import Engine\nfrom wtfml.data_loaders.image import ClassificationLoader\n\nimport pretrainedmodels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SEResnext50_32x4d(nn.Module):\n    def __init__(self, pretrained='imagenet'):\n        super(SEResnext50_32x4d, self).__init__()\n        \n        self.base_model = pretrainedmodels.__dict__[\n            \"se_resnext50_32x4d\"\n        ](pretrained=None)\n        #print (self.base_model)\n        if pretrained is not None:\n            self.base_model.load_state_dict(\n                torch.load(\n                    \"../input/pretrained-model-weights-pytorch/se_resnext50_32x4d-a260b3a4.pth\"\n                )\n            )\n\n        self.l0 = nn.Linear(2048, 1)\n    \n    def forward(self, image):\n        batch_size, _, _, _ = image.shape\n        \n        x = self.base_model.features(image)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n        \n        out = self.l0(x)\n      #  loss = nn.BCEWithLogitsLoss()(out, targets.view(-1, 1).type_as(x))\n        out = torch.sigmoid(out)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weighted_cross_entropy_loss(prediction, target, weights= ([0.02 , 0.98])):        # 0.98 for '0' class and 0.02 for positive class\n    target = target.view(-1,1)    \n    if weights is not None:\n        assert len(weights) == 2\n        \n        loss = weights[0] * (target.cpu() * torch.log(prediction.cpu())) + \\\n               weights[1] * ((1 - target) * torch.log(1 - prediction.cpu()))\n    else:\n        loss = target * torch.log(prediction) + (1 - target) * torch.log(1 - prediction)\n\n    return torch.neg(torch.mean(loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = weighted_cross_entropy_loss(prediction, target)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create folds\ndf = pd.read_csv(\"../input/siim-isic-melanoma-classification/train.csv\")\ndf[\"kfold\"] = -1    \n#print (df.head())\ndf = df.sample(frac=1).reset_index(drop=True)\n#print (df.head())\ny = df.target.values\n#print(len(y))\na =y[y==0]\n#print (len(a))\nkf = model_selection.StratifiedKFold(n_splits=5)\nprint(len(df))\na = (df[\"image_name\"][1])\nprint((a))\n#for i in range(0,len(a)):\n #   print(a[i])\nfor f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n #   print (t_,v_) \n  #  print (f)\n    df.loc[v_, 'kfold'] = f\n\n\n#print (df)    \ndf.to_csv(\"train_folds.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MelenomaDataset(Dataset):\n    def __init__(self, img_path, df,transform = None):\n        self.image_path = img_path\n        \n        self.data_frame = df\n        self.transforms = transform\n    def __len__(self):\n        return (len(self.data_frame))\n   \n    def __getitem__(self, index):\n       # print(df[\"image_name\"][index])\n        path = os.path.join(self.image_path, self.data_frame[\"image_name\"][index]+\".png\")\n        \n        image = cv2.imread(path, cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        #image /= 255.0\n\n        \n        label = self.data_frame[\"target\"][index]\n        if self.transforms is not None:\n            image = self.transforms(image)\n        \n        return {\"image\" :image,\"label\" : label}\n        \n\n\"\"\"        \nuse_gpu = torch.cuda.is_available()\nroot_dir = \"../input/siic-isic-224x224-images/train/\"\n\ntrain_dataset = MelenomaDataset(root_dir,df)\nimage , label = train_dataset.__getitem__(1)\n#print(image.shape)\nfor ind,pack in enumerate(train_dataset):\n    data = pack[\"image\"]  \n        # print(data.shape)\n    #data=data.numpy()\n    #print(data.shape)\n    # data=data.reshape(data.shape[1],data.shape[2],data.shape[0])\n    data = data.permute(1, 2, 0)\n   # print(data.shape)\n    plt.imshow(data)\n    plt.show()       \n    \"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageMeter:\n    \"\"\"\n    Computes and stores the average and current value\n    \"\"\"\n\n    def __init__(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validation(fold, valid_loader,valid_targets,model):\n    tk0 = tqdm(valid_loader, total=len(valid_loader)) \n    final_predictions =[]\n    model.eval()\n    #print (tk0)\n    losses_valid =AverageMeter()\n    with torch.no_grad():\n        for idx, pack in enumerate(tk0):\n            \n            prediction = model(pack[\"image\"].cuda())\n            loss = weighted_cross_entropy_loss(prediction,pack[\"label\"])\n            #running_loss += loss.item()*pack[\"image\"].size(0)\n            losses_valid.update(loss.item(), valid_loader.batch_size)\n            tk0.set_postfix(loss=losses_valid.avg)\n            final_predictions.append(prediction.cpu())\n        \n        tk0.close()\n    \n    auc = metrics.roc_auc_score(valid_targets,np.vstack(final_predictions).ravel() )\n    \n    return losses_valid.avg,auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(fold):\n    training_data_path = \"../input/siic-isic-224x224-images/train/\"\n    df = pd.read_csv(\"/kaggle/working/train_folds.csv\")\n    device = \"cuda\"\n    epochs = 50\n    train_bs = 32\n    valid_bs = 16\n\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    valid_targets = df_valid.target.values\n    #print(valid_targets.shape)\n    model = SEResnext50_32x4d(pretrained=\"imagenet\")\n    model.to(device)\n\n    mean = (0.485, 0.456, 0.406)\n    std = (0.229, 0.224, 0.225)\n    transform_train = transforms.Compose([\n     transforms.ToPILImage(),\n     transforms.RandomHorizontalFlip(p=0.5),\n     transforms.RandomRotation(degrees=(-90, 90)),\n     transforms.RandomVerticalFlip(p=0.5),\n     transforms.ToTensor(),\n     transforms.Normalize(mean, std),\n     ])\n    \n    transform_valid = transforms.Compose([\n     #transforms.ToPILImage(),\n     transforms.ToTensor(),\n     transforms.Normalize(mean, std),\n     ])\n   \n    train_data = MelenomaDataset(training_data_path, df_train, transform_train)\n    valid_data = MelenomaDataset(training_data_path,df_valid,transform_valid)\n    \n    train_loader = DataLoader(train_data, batch_size= train_bs, shuffle =False, num_workers=4)\n    \n    valid_loader = DataLoader(valid_data,batch_size = valid_bs, shuffle = False, num_workers = 4)\n    \n   \n\n\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer,\n        patience=3,\n        threshold=0.001,\n        mode=\"max\"\n    )\n\n    es = EarlyStopping(patience=5, mode=\"max\")\n    \n    #loss_v , auc = validation(fold,valid_loader,valid_targets,model) \n     \n    for epoch in range(epochs):\n        count = 0\n        tk0 = tqdm(train_loader, total=len(train_loader)) \n        #print (tk0)\n        losses =AverageMeter()\n        for idx, pack in enumerate(tk0):\n            \n            if (idx == 0):\n                optimizer.zero_grad()\n            model.train()\n            prediction = model(pack[\"image\"].cuda())\n            loss = weighted_cross_entropy_loss(prediction,pack[\"label\"])\n            #running_loss += loss.item()*pack[\"image\"].size(0)\n            loss.backward()\n            optimizer.step()\n            scheduler.step(loss)\n            optimizer.zero_grad()\n            losses.update(loss.item(), train_loader.batch_size)\n            tk0.set_postfix(loss=losses.avg)\n            \n        \n        print (epoch)\n        print (f\"training_loss for {epoch} = {losses.avg}\")    \n        loss_v , auc = validation(fold,valid_loader,valid_targets,model) \n    \n        print (f\"validation_loss for {epoch}= {loss_v}\")\n        print(f\"Epoch = {epoch}, AUC = {auc}\")\n        \n        es(auc, model, model_path=f\"model_fold_{fold}.bin\")\n        if es.early_stop:\n            print(\"Early stopping\")\n            break        \n        \n        \n    tk0.close()\n                \n          \n            #print (target.shape())\n        \n        #train_loss = criterion(outs)\n        #predictions, valid_loss = Engine.evaluate(\n        #    valid_loader, model, device=device\n        #)\n        #predictions = np.vstack((predictions)).ravel()\n        #auc = metrics.roc_auc_score(valid_targets, predictions)\n       # print(f\"Epoch = {epoch}, AUC = {auc}\")\n       # scheduler.step(auc)\n\n        #es(auc, model, model_path=f\"model_fold_{fold}.bin\")\n        #if es.early_stop:\n         #   print(\"Early stopping\")\n          #  break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(fold):\n    test_data_path = \"../input/siic-isic-224x224-images/test/\"\n    df = pd.read_csv(\"../input/siim-isic-melanoma-classification/test.csv\")\n    device = \"cuda\"\n    model_path=f\"model_fold_{fold}.bin\"\n\n    mean = (0.485, 0.456, 0.406)\n    std = (0.229, 0.224, 0.225)\n    aug = albumentations.Compose(\n        [\n            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n        ]\n    )\n\n    images = df.image_name.values.tolist()\n    images = [os.path.join(test_data_path, i + \".png\") for i in images]\n    targets = np.zeros(len(images))\n\n    test_dataset = ClassificationLoader(\n        image_paths=images,\n        targets=targets,\n        resize=None,\n        augmentations=aug,\n    )\n\n    test_loader = torch.utils.data.DataLoader(\n        test_dataset, batch_size=16, shuffle=False, num_workers=4\n    )\n\n    model = SEResnext50_32x4d(pretrained=None)\n    model.load_state_dict(torch.load(model_path))\n    model.to(device)\n\n    predictions = Engine.predict(test_loader, model, device=device)\n    predictions = np.vstack((predictions)).ravel()\n\n    return predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(0)\ntrain(1)\ntrain(2)\ntrain(3)\ntrain(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p1 = predict(0)\np2 = predict(1)\np3 = predict(2)\np4 = predict(3)\np5 = predict(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = (p1 + p2 + p3 + p4 + p5) / 5\nsample = pd.read_csv(\"../input/siim-isic-melanoma-classification/sample_submission.csv\")\nsample.loc[:, \"target\"] = predictions\nsample.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}